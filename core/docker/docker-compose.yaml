# RooCode Local Agent System - Docker Compose Configuration
# Orchestrated services for LLM and API with proper volume mapping

version: '3.8'

services:
  roo-system:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: roo-system
    image: neomint/roo-agent-buddy:latest
    
    # Port mappings for API access
    ports:
      - "8080:8080"   # API Server
      - "11434:11434" # LLM Engine (llama.cpp/Ollama compatible)
    
    # Volume mappings for persistent data and configuration - Task 39
    volumes:
      # Mount entire project to /project as specified in Task 39
      - .:/project

      # Additional named volumes for persistence
      - models:/project/models
      - logs:/project/logs
      - data:/project/data
    
    # Environment variables from .env.docker
    env_file:
      - .env.docker
    
    environment:
      - PROFILE=${PROFILE:-buddy}
      - API_PORT=${API_PORT:-8080}
      - LLM_PORT=${LLM_PORT:-11434}
      - RUNTIME_MODE=${RUNTIME_MODE:-production}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - PYTHONPATH=/app
      - PYTHONUNBUFFERED=1
    
    # Restart policy for production
    restart: unless-stopped
    
    # Health check
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    
    # Resource limits
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'
    
    # Network configuration
    networks:
      - roo-network

# Named volumes for persistent data
volumes:
  models:
    driver: local
  logs:
    driver: local
  data:
    driver: local

# Custom network for service communication
networks:
  roo-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
